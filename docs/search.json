[
  {
    "objectID": "posts/ABC_week02_time_series_anomaly/index.html",
    "href": "posts/ABC_week02_time_series_anomaly/index.html",
    "title": "[2025 ABC 프로젝트 멘토링 8기] 2주차 - 시계열 이상 탐지와 머신러닝 기초 적용",
    "section": "",
    "text": "안녕하세요 이번 포스트는 ABC 프로젝트 멘토링 8기 2주차 실습 기록입니다. 지난주엔 시계열 데이터 EDA랑 전처리만 했는데, 이번엔 간단한 머신러닝 모델로 이상치 탐지 기법을 소개하려 합니다."
  },
  {
    "objectID": "posts/ABC_week02_time_series_anomaly/index.html#데이터-준비",
    "href": "posts/ABC_week02_time_series_anomaly/index.html#데이터-준비",
    "title": "[2025 ABC 프로젝트 멘토링 8기] 2주차 - 시계열 이상 탐지와 머신러닝 기초 적용",
    "section": "1. 데이터 준비",
    "text": "1. 데이터 준비\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import IsolationForest\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nnp.random.seed(42)\nt = np.arange(0, 100, 1)\ny = np.sin(0.2 * t) + np.random.normal(0, 0.2, size=len(t))\n# 여러 위치에 인위적으로 이상치 추가\noutlier_indices = [15, 35, 55, 75, 90]\noutlier_values = [2, -2, 2.5, -2.5, 3]\nfor idx, val in zip(outlier_indices, outlier_values):\n    y[idx] += val\ndf = pd.DataFrame({'time': t, 'value': y})\n\n\nplt.figure(figsize=(10,4))\nplt.plot(df['time'], df['value'], label='시계열 데이터')\nplt.scatter(df.loc[outlier_indices, 'time'], df.loc[outlier_indices, 'value'], color='red', label='부여한 이상값')\nplt.legend()\nplt.title('이상값이 포함된 시계열 데이터')\nplt.show()\n\n\n\n\n이상값이 포함된 시계열 데이터"
  },
  {
    "objectID": "posts/ABC_week02_time_series_anomaly/index.html#머신러닝-기반-이상-탐지-isolation-forest-dbscan-one-class-svm",
    "href": "posts/ABC_week02_time_series_anomaly/index.html#머신러닝-기반-이상-탐지-isolation-forest-dbscan-one-class-svm",
    "title": "[2025 ABC 프로젝트 멘토링 8기] 2주차 - 시계열 이상 탐지와 머신러닝 기초 적용",
    "section": "2. 머신러닝 기반 이상 탐지 (Isolation Forest, DBSCAN, One-Class SVM)",
    "text": "2. 머신러닝 기반 이상 탐지 (Isolation Forest, DBSCAN, One-Class SVM)\n\n모델별 특징 및 한계\n\n\n\n\n\n\n\n\n모델\n장점\n한계/주의점\n\n\n\n\nIsolation Forest\n대용량/고차원 데이터에 강함, 빠름\n이상치 비율(contamination) 추정 필요\n\n\nDBSCAN\n군집/밀도 기반, 파라미터 직관적\neps, min_samples에 민감, 1차원 한계\n\n\nOne-Class SVM\n비선형 경계, 소규모 데이터에 적합\n느릴 수 있음, 파라미터 튜닝 필요\n\n\n\n\n\nIsolation Forest\n\nfrom sklearn.ensemble import IsolationForest\nmodel = IsolationForest(contamination=0.05, random_state=42)\ndf['anomaly_isof'] = model.fit_predict(df[['value']])\n\n\nplt.figure(figsize=(10,4))\nplt.plot(df['time'], df['value'], label='시계열 데이터')\nplt.scatter(df[df['anomaly_isof']==-1]['time'], df[df['anomaly_isof']==-1]['value'], color='red', label='탐지된 이상값')\nplt.legend()\nplt.title('Isolation Forest 기반 이상 탐지 결과')\nplt.show()\n\n\n\n\nIsolation Forest 기반 이상 탐지 결과\n\n\n\n\n\n\nDBSCAN (밀도 기반 이상 탐지)\n\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(df[['value']])\ndbscan = DBSCAN(eps=0.25, min_samples=3)  # eps와 min_samples를 조정해 민감도 조정\ndf['anomaly_dbscan'] = dbscan.fit_predict(X_scaled)\n\n\nplt.figure(figsize=(10,4))\nplt.plot(df['time'], df['value'], label='시계열 데이터')\nplt.scatter(df[df['anomaly_dbscan']==-1]['time'], df[df['anomaly_dbscan']==-1]['value'], color='orange', label='탐지된 이상값(DBSCAN)')\nplt.legend()\nplt.title('DBSCAN 기반 이상 탐지 결과')\nplt.show()\n\n\n\n\nDBSCAN 기반 이상 탐지 결과\n\n\n\n\n\n\nOne-Class SVM (서포트 벡터 머신 기반 이상 탐지)\n\nfrom sklearn.svm import OneClassSVM\n# 기본 파라미터로는 이상치 탐지가 잘 안 됨 (F1이 0.14 수준)\nocsvm = OneClassSVM(nu=0.05, kernel='rbf', gamma='auto')\ndf['anomaly_ocsvm'] = ocsvm.fit_predict(df[['value']])\n\n\nplt.figure(figsize=(10,4))\nplt.plot(df['time'], df['value'], label='시계열 데이터')\nplt.scatter(df[df['anomaly_ocsvm']==-1]['time'], df[df['anomaly_ocsvm']==-1]['value'], color='purple', label='탐지된 이상값(OCSVM)')\nplt.legend()\nplt.title('One-Class SVM 기반 이상 탐지 결과')\nplt.show()\n\n\n\n\nOne-Class SVM 기반 이상 탐지 결과\n\n\n\n\n\nSVM 파라미터 튜닝 시도\n\n# gamma 값을 더 크게, nu 값을 더 높게 조정해서 민감도를 높임\nocsvm_tuned = OneClassSVM(nu=0.12, kernel='rbf', gamma=2)\ndf['anomaly_ocsvm_tuned'] = ocsvm_tuned.fit_predict(df[['value']])\n\n\nplt.figure(figsize=(10,4))\nplt.plot(df['time'], df['value'], label='시계열 데이터')\nplt.scatter(df[df['anomaly_ocsvm_tuned']==-1]['time'], df[df['anomaly_ocsvm_tuned']==-1]['value'], color='blue', label='탐지된 이상값(튜닝 SVM)')\nplt.legend()\nplt.title('튜닝된 One-Class SVM 기반 이상 탐지 결과')\nplt.show()\n\n\n\n\n튜닝된 One-Class SVM 이상 탐지 결과\n\n\n\n\n\n\n\n이상치 탐지 및 평가지표(Precision, Recall, F1)\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\ndef anomaly_metrics(true_outliers, pred_outliers, n):\n    true = [1 if i in true_outliers else 0 for i in range(n)]\n    pred = [1 if i in pred_outliers else 0 for i in range(n)]\n    p = precision_score(true, pred)\n    r = recall_score(true, pred)\n    f1 = f1_score(true, pred)\n    return p, r, f1\n\nn = len(df)\ntrue_outliers = outlier_indices\npred_isof = df.index[df['anomaly_isof']==-1].tolist()\np_isof, r_isof, f1_isof = anomaly_metrics(true_outliers, pred_isof, n)\npred_dbscan = df.index[df['anomaly_dbscan']==-1].tolist()\np_dbscan, r_dbscan, f1_dbscan = anomaly_metrics(true_outliers, pred_dbscan, n)\npred_ocsvm = df.index[df['anomaly_ocsvm']==-1].tolist()\np_ocsvm, r_ocsvm, f1_ocsvm = anomaly_metrics(true_outliers, pred_ocsvm, n)\npred_ocsvm_tuned = df.index[df['anomaly_ocsvm_tuned']==-1].tolist()\np_ocsvm_t, r_ocsvm_t, f1_ocsvm_t = anomaly_metrics(true_outliers, pred_ocsvm_tuned, n)\n\nprint(f\"Isolation Forest - Precision: {p_isof:.2f}, Recall: {r_isof:.2f}, F1: {f1_isof:.2f}\")\nprint(f\"DBSCAN           - Precision: {p_dbscan:.2f}, Recall: {r_dbscan:.2f}, F1: {f1_dbscan:.2f}\")\nprint(f\"One-Class SVM    - Precision: {p_ocsvm:.2f}, Recall: {r_ocsvm:.2f}, F1: {f1_ocsvm:.2f}\")\nprint(f\"튜닝 SVM         - Precision: {p_ocsvm_t:.2f}, Recall: {r_ocsvm_t:.2f}, F1: {f1_ocsvm_t:.2f}\")\n\nIsolation Forest - Precision: 1.00, Recall: 1.00, F1: 1.00\nDBSCAN           - Precision: 1.00, Recall: 1.00, F1: 1.00\nOne-Class SVM    - Precision: 0.14, Recall: 0.40, F1: 0.21\n튜닝 SVM         - Precision: 0.21, Recall: 1.00, F1: 0.34"
  },
  {
    "objectID": "posts/ABC_week02_time_series_anomaly/index.html#결과-해석-및-정리",
    "href": "posts/ABC_week02_time_series_anomaly/index.html#결과-해석-및-정리",
    "title": "[2025 ABC 프로젝트 멘토링 8기] 2주차 - 시계열 이상 탐지와 머신러닝 기초 적용",
    "section": "3. 결과 해석 및 정리",
    "text": "3. 결과 해석 및 정리\n\nOne-Class SVM은 기본 파라미터로는 이상치 탐지가 잘 되지 않았으나, gamma와 nu를 조정해 튜닝하면 성능이 개선되는 것을 확인할 수 있다. 이 과정에서 파라미터 튜닝의 중요성을 경험했다.\n각 모델별로 이상치 탐지 결과와 평가지표(Precision, Recall, F1)가 다르게 나타난다. Isolation Forest는 인위적으로 넣은 이상치를 대부분 탐지했고, DBSCAN은 파라미터에 따라 민감하게 반응한다. One-Class SVM은 데이터 분포와 파라미터에 따라 결과가 크게 달라진다.\nPrecision(정밀도), Recall(재현율), F1-score는 모델의 이상치 탐지 성능을 종합적으로 평가하는 지표로, 실제 데이터 분석에서는 여러 방법을 비교하고 도메인 지식과 함께 해석하는 것이 중요하다."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "beomdo's ML-DL blog",
    "section": "",
    "text": "[2025 ABC 프로젝트 멘토링 8기] 3주차 - CNN으로 시계열 이상 탐지 (PyTorch)\n\n\n\nABC프로젝트멘토링\n\n유클리드소프트\n\n고용노동부\n\n대한상공회의소\n\n미래내일일경험사업\n\nPyTorch\n\n\n\nPyTorch를 사용하여 1D CNN 오토인코더 기반 시계열 이상 탐지 베이스라인 모델을 구현합니다.\n\n\n\n\n\nJun 8, 2025\n\n\nBeomdo Park\n\n12 min\n\n\n\n\n\n\n\n\n\n\n\n[2025 ABC 프로젝트 멘토링 8기] 2주차 - 시계열 이상 탐지와 머신러닝 기초 적용\n\n\n\nABC프로젝트멘토링\n\n유클리드소프트\n\n고용노동부\n\n대한상공회의소\n\n미래내일일경험사업\n\n\n\nPython을 활용한 시계열 데이터 이상 탐지 - 머신러닝 기법 적용 실습\n\n\n\n\n\nJun 1, 2025\n\n\nBeomdo Park\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n[2025 ABC 프로젝트 멘토링 8기] 1주차 - 시계열 이상 탐지를 위한 EDA 및 전처리\n\n\n\nABC프로젝트멘토링\n\n유클리드소프트\n\n고용노동부\n\n대한상공회의소\n\n미래내일일경험사업\n\n\n\nPython을 활용한 시계열 데이터 이상 탐지를 위한 기본 EDA 및 전처리 방법을 다룹니다.\n\n\n\n\n\nMay 25, 2025\n\n\nBeomdo Park\n\n8 min\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "컴퓨터공학과 3학년입니다.\n\nData Scientist AI-powered problem solver who applies research and technology to real-world challenges."
  },
  {
    "objectID": "posts/ABC_week01_data analysis/index.html",
    "href": "posts/ABC_week01_data analysis/index.html",
    "title": "[2025 ABC 프로젝트 멘토링 8기] 1주차 - 시계열 이상 탐지를 위한 EDA 및 전처리",
    "section": "",
    "text": "유클리드소프트에서 진행하는 ABC 프로젝트 멘토링에 8기로 참여하게 되었습니다.   [산업 전력 데이터의 이상치 탐지 성능 향상 솔루션 구축]을 주제로 다양한 데이터 분석 및 인공지능 기법을 학습하고 실제 프로젝트에 적용해볼 예정입니다."
  },
  {
    "objectID": "posts/ABC_week01_data analysis/index.html#시계열-데이터란",
    "href": "posts/ABC_week01_data analysis/index.html#시계열-데이터란",
    "title": "[2025 ABC 프로젝트 멘토링 8기] 1주차 - 시계열 이상 탐지를 위한 EDA 및 전처리",
    "section": "시계열 데이터란?",
    "text": "시계열 데이터란?\n시계열 데이터(Time Series Data)는 일정 시간 간격으로 기록된 데이터 포인트들의 순차적인 집합입니다. 예를 들어, 시간별 산업 설비의 전력 사용량, 일별 주가, 월별 웹사이트 방문자 수 등이 시계열 데이터에 해당합니다. 이러한 데이터는 시간의 흐름에 따른 변화와 패턴을 분석하는 데 사용되며, 특히 정상적인 패턴에서 벗어나는 ’이상치’를 탐지하는 데 중요한 기초 자료가 됩니다.\n시계열 데이터는 주로 다음과 같은 특징을 가집니다:\n\n추세 (Trend): 데이터가 장기적으로 증가하거나 감소하는 경향.\n계절성 (Seasonality): 특정 주기(예: 하루, 주, 월)에 따라 반복되는 패턴.\n주기성 (Cyclicality): 계절성보다 긴, 고정되지 않은 주기의 변동.\n불규칙 변동 (Irregular Fluctuations/Noise): 위 요소들로 설명되지 않는 무작위적 변동."
  },
  {
    "objectID": "posts/ABC_week01_data analysis/index.html#시계열-이상-탐지에서-eda와-전처리의-중요성",
    "href": "posts/ABC_week01_data analysis/index.html#시계열-이상-탐지에서-eda와-전처리의-중요성",
    "title": "[2025 ABC 프로젝트 멘토링 8기] 1주차 - 시계열 이상 탐지를 위한 EDA 및 전처리",
    "section": "시계열 이상 탐지에서 EDA와 전처리의 중요성",
    "text": "시계열 이상 탐지에서 EDA와 전처리의 중요성\n이상치(Anomaly) 또는 특이점(Outlier)은 일반적인 데이터 패턴에서 현저하게 벗어나는 관측치를 의미합니다. 산업 전력 데이터에서 이상치는 설비 고장, 에너지 누수, 비정상적 공정 운영 등 중요한 문제를 시사할 수 있습니다. 효과적인 이상 탐지를 위해서는 데이터에 대한 깊이 있는 이해가 선행되어야 하며, 탐색적 데이터 분석(EDA)과 적절한 전처리는 이 과정의 핵심입니다.\nEDA와 전처리가 중요한 이유:\n\n데이터 특성 파악: 데이터의 분포, 추세, 계절성 등 기본적인 통계적 특성을 이해하여 ‘정상’ 상태의 기준을 설정하는 데 도움을 줍니다.\n잠재적 이상치 식별: 시각화 등을 통해 예상치 못한 급증, 급감 또는 패턴 변화를 초기에 발견할 수 있습니다.\n데이터 품질 향상: 결측치 처리, 노이즈 제거 등을 통해 분석의 정확도를 높입니다.\n피처 엔지니어링 기반 마련: 분석 목적에 맞는 새로운 변수를 생성하거나 기존 변수를 변환하는 데 필요한 통찰력을 제공합니다.\n적절한 이상 탐지 모델 선택 지원: 데이터의 특성에 맞는 이상 탐지 알고리즘을 선택하는 데 중요한 정보를 제공합니다."
  },
  {
    "objectID": "posts/ABC_week01_data analysis/index.html#python을-이용한-시계열-데이터-eda-및-전처리-기초",
    "href": "posts/ABC_week01_data analysis/index.html#python을-이용한-시계열-데이터-eda-및-전처리-기초",
    "title": "[2025 ABC 프로젝트 멘토링 8기] 1주차 - 시계열 이상 탐지를 위한 EDA 및 전처리",
    "section": "Python을 이용한 시계열 데이터 EDA 및 전처리 기초",
    "text": "Python을 이용한 시계열 데이터 EDA 및 전처리 기초\nPython의 pandas, numpy, matplotlib, seaborn 라이브러리를 사용하여 산업 전력 사용량 데이터를 가정하고, 이상 탐지를 위한 기본적인 EDA 및 전처리 과정을 살펴보겠습니다.\n\n1. 필요한 라이브러리 불러오기\n데이터 분석 및 시각화에 필요한 라이브러리를 가져옵니다.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns # 향상된 시각화를 위한 Seaborn\nfrom datetime import datetime\n\n# 경고 메시지 무시 (선택 사항)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\n2. 분석용 샘플 시계열 데이터 생성 (가상 산업 전력 사용량)\n실제 산업 전력 데이터와 유사한 특성을 갖도록 가상 데이터를 생성합니다. 여기에는 일정한 기본 사용량, 약간의 증가 추세, 주간 계절성(평일 사용량 증가, 주말 감소), 그리고 몇 개의 인위적인 이상치(스파이크 및 급감)를 포함시킵니다.\n\n# 재현성을 위한 시드 설정\nnp.random.seed(42)\n\n# 날짜 범위 생성 (약 1년)\ndate_rng = pd.date_range(start='2025-01-01', periods=365, freq='D')\ndata = pd.DataFrame(date_rng, columns=['date'])\n\n# 기본 전력 사용량 설정 및 추세 생성\nbaseline_usage = 100  # 기본 사용량 (예: kWh)\ntrend_factor = np.linspace(0, 20, len(date_rng)) # 선형 증가 추세\n\n# 주간 계절성 생성 (월:0 ~ 일:6)\n# 산업 데이터 특성상 평일 사용량 높고, 주말 낮음\nday_of_week_effect = np.array([15, 18, 20, 19, 17, 5, 3])\nseasonal_factor = np.array([day_of_week_effect[day.weekday()] for day in date_rng])\n\n# 임의의 노이즈 생성\nnoise = np.random.normal(0, 5, size=(len(date_rng))) # 평균 0, 표준편차 5\n\n# 데이터 생성 (전력 사용량 = 기본값 + 추세 + 계절성 + 노이즈)\ndata['power_usage'] = baseline_usage + trend_factor + seasonal_factor + noise\n\n# 인위적인 이상치(스파이크 및 급감) 추가\ndata.loc[data.index[50], 'power_usage'] += 70  # 51번째 날에 큰 스파이크\ndata.loc[data.index[150], 'power_usage'] -= 50 # 151번째 날에 큰 폭 하락\ndata.loc[data.index[250], 'power_usage'] += 80  # 251번째 날에 큰 스파이크\n\n# 데이터 값 보정 (음수 방지 및 최소값 설정)\ndata['power_usage'] = data['power_usage'].astype(float).clip(lower=10)\n\n# 'date' 컬럼을 인덱스로 설정\ndata.set_index('date', inplace=True)\n\nprint(\"생성된 가상 전력 사용량 데이터 샘플 (상위 5개):\")\nprint(data.head())\nprint(\"\\n생성된 가상 전력 사용량 데이터 샘플 (하위 5개):\")\nprint(data.tail())\n\n생성된 가상 전력 사용량 데이터 샘플 (상위 5개):\n            power_usage\ndate                   \n2025-01-01   122.483571\n2025-01-02   118.363624\n2025-01-03   120.348333\n2025-01-04   112.779984\n2025-01-05   102.049013\n\n생성된 가상 전력 사용량 데이터 샘플 (하위 5개):\n            power_usage\ndate                   \n2025-12-27   127.376952\n2025-12-28   130.498859\n2025-12-29   134.346309\n2025-12-30   139.953614\n2025-12-31   143.450720\n\n\n이 샘플 데이터는 power_usage라는 이름으로 전력 사용량 정보를 가지며, EDA 과정에서 이상치를 시각적으로 탐색하는 데 사용됩니다.\n\n\n\n3. 데이터 기본 탐색\n데이터의 구조와 기본적인 통계적 특성을 확인합니다.\n\nprint(\"데이터 정보:\")\ndata.info()\n\nprint(\"\\n기술 통계량:\")\nprint(data.describe())\n\nprint(f\"\\n결측치 확인: {data.isnull().sum().sum()} 개\")\n# data.isnull().sum() # 컬럼별 결측치 확인\n\n데이터 정보:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 365 entries, 2025-01-01 to 2025-12-31\nData columns (total 1 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   power_usage  365 non-null    float64\ndtypes: float64(1)\nmemory usage: 5.7 KB\n\n기술 통계량:\n       power_usage\ncount   365.000000\nmean    124.197677\nstd      11.877300\nmin      64.494222\n25%     117.423353\n50%     124.093359\n75%     131.043033\nmax     202.431844\n\n결측치 확인: 0 개\n\n\ninfo()는 데이터 타입, 인덱스 정보, 메모리 사용량 등을 보여줍니다. describe()는 평균, 표준편차, 최소/최대값, 사분위수 등 주요 기술 통계량을 제공하여 데이터의 전반적인 분포를 파악하는 데 도움을 줍니다. 결측치가 있다면 이상 탐지 분석 전에 적절히 처리(예: 보간, 제거)해야 합니다. 이 샘플에서는 결측치가 없습니다.\n\n\n\n4. 주요 시각화를 통한 탐색적 데이터 분석 (EDA)\n시각화는 시계열 데이터의 패턴과 잠재적 이상치를 발견하는 데 매우 효과적입니다.\n\n4.1. 기본 시계열 플롯\n전체 기간에 대한 전력 사용량 변화를 시각화하여 추세, 계절성, 그리고 눈에 띄는 이상 패턴을 관찰합니다.\n\nplt.figure(figsize=(9, 6))\nplt.plot(data.index, data['power_usage'], label='일별 전력 사용량', color='dodgerblue', linewidth=1.5)\nplt.title('일별 가상 산업 전력 사용량', fontsize=16)\nplt.xlabel('날짜', fontsize=12)\nplt.ylabel('전력 사용량 (kWh)', fontsize=12)\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\nFigure 1: 일별 가상 산업 전력 사용량\n\n\n\n\n\n위 그래프에서 전반적인 증가 추세와 주기적인 변동(계절성) 외에도, 몇몇 지점에서 급격한 스파이크나 하락(우리가 삽입한 이상치)이 시각적으로 확인됩니다. 실제 데이터 분석 시 이러한 지점들이 조사 대상이 됩니다.\n\n\n\n4.2. 데이터 분포 확인 (히스토그램 및 KDE)\n전력 사용량 값들의 분포를 확인하여 데이터가 특정 구간에 집중되어 있는지, 또는 분포에서 벗어나는 값들이 있는지 살펴봅니다.\n\nplt.figure(figsize=(10, 6))\nsns.histplot(data['power_usage'], kde=True, color='mediumseagreen', bins=30)\nplt.title('전력 사용량 분포 (히스토그램 및 KDE)', fontsize=16)\nplt.xlabel('전력 사용량 (kWh)', fontsize=12)\nplt.ylabel('빈도', fontsize=12)\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.show()\n\n\n\n\n\n\n\nFigure 2: 전력 사용량 분포\n\n\n\n\n\n히스토그램과 KDE(Kernel Density Estimate) 플롯은 데이터 값의 분포를 보여줍니다. 만약 분포의 꼬리 부분에 값이 드물게 나타난다면 이는 이상치일 가능성이 있습니다. 우리가 삽입한 인위적인 스파이크 값들이 분포의 오른쪽 꼬리 부분에 나타날 수 있습니다.\n\n\n\n4.3. 주기적 패턴 확인 (요일별 Box Plot)\n산업 데이터는 요일이나 월별로 뚜렷한 주기성을 가질 수 있습니다. Box plot을 사용하면 이러한 주기성 내에서 평소와 다른 패턴을 보이는 시점을 파악하는 데 유용합니다.\n\n# 분석을 위해 'day_of_week' 컬럼 추가 (월요일=0, 일요일=6)\ndata['day_of_week'] = data.index.dayofweek\n\nplt.figure(figsize=(9, 5))\nsns.boxplot(x='day_of_week', y='power_usage', data=data, palette='coolwarm')\nplt.title('요일별 전력 사용량 분포', fontsize=16)\nplt.xlabel('요일 (0:월, 1:화, 2:수, 3:목, 4:금, 5:토, 6:일)', fontsize=12)\nplt.ylabel('전력 사용량 (kWh)', fontsize=12)\nplt.xticks(ticks=range(7), labels=['월', '화', '수', '목', '금', '토', '일'])\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.show()\n\n\n\n\n\n\n\nFigure 3: 요일별 전력 사용량 분포\n\n\n\n\n\n요일별 Box plot은 각 요일의 전력 사용량 분포를 보여줍니다. 각 박스는 해당 요일 데이터의 중앙 50%(IQR: Interquartile Range)를 나타내며, 박스 외부의 점들은 잠재적인 이상치(outliers)를 의미합니다. 이 샘플에서는 주말(토, 일) 사용량이 평일보다 낮은 패턴이 뚜렷하며, 우리가 인위적으로 삽입한 이상치들이 특정 요일의 일반적인 범위를 벗어나 점으로 표시될 수 있습니다. 예를 들어, 화요일(1)에 발생시킨 스파이크는 화요일의 박스 플롯에서 상단 이상치로 나타날 가능성이 큽니다.\n\n\n\n\n5. 이동 평균을 활용한 추세 및 변동성 관찰\n이동 평균(Moving Average)은 단기적인 변동을 완화하여 장기적인 추세를 파악하거나, 데이터의 일반적인 수준을 나타내는 기준으로 활용될 수 있습니다. 원본 데이터와 이동 평균선을 함께 시각화하면, 이동 평균에서 크게 벗어나는 지점들을 이상치 후보로 간주할 수 있습니다.\n\n# 7일 이동 평균 계산\ndata['rolling_mean_7'] = data['power_usage'].rolling(window=7, center=True).mean() # center=True로 설정하여 lag 감소 효과\n\nplt.figure(figsize=(9, 6))\nplt.plot(data.index, data['power_usage'], label='일별 전력 사용량', color='lightskyblue', alpha=0.8, linewidth=1)\nplt.plot(data.index, data['rolling_mean_7'], label='7일 이동 평균 (중앙 정렬)', color='orangered', linewidth=2)\nplt.title('일별 전력 사용량 및 7일 이동 평균', fontsize=16)\nplt.xlabel('날짜', fontsize=12)\nplt.ylabel('전력 사용량 (kWh)', fontsize=12)\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\nFigure 4: 전력 사용량과 7일 이동 평균\n\n\n\n\n\n\n# 이동 평균과의 차이(잔차와 유사한 개념)를 통해 이상치 강조\ndata['deviation_from_ma'] = data['power_usage'] - data['rolling_mean_7']\n\nplt.figure(figsize=(9,5))\nplt.plot(data.index, data['deviation_from_ma'], label='이동 평균과의 편차', color='teal', linewidth=1, marker='o', markersize=3, linestyle='None')\nplt.axhline(0, color='black', linestyle='--', linewidth=0.8) # 기준선\n\n# 편차의 임계값을 설정하여 이상치 후보 시각화 (예: 편차의 표준편차 기반)\n# 이동 평균 계산 시 초반/후반 NaN 값이 있을 수 있으므로 dropna() 사용\ndeviation_std = data['deviation_from_ma'].dropna().std()\nupper_threshold = 3 * deviation_std\nlower_threshold = -3 * deviation_std\n\nplt.axhline(upper_threshold, color='red', linestyle=':', linewidth=1.5, label=f'+3σ ({upper_threshold:.2f})')\nplt.axhline(lower_threshold, color='red', linestyle=':', linewidth=1.5, label=f'-3σ ({lower_threshold:.2f})')\nplt.title('이동 평균과의 편차 (이상치 탐색 보조)', fontsize=16)\nplt.xlabel('날짜', fontsize=12)\nplt.ylabel('편차 (kWh)', fontsize=12)\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.show()\n\n\n\n\n\n\n\nFigure 5: 이동 평균과의 편차 (이상치 탐색 보조)\n\n\n\n\n\n7일 이동 평균선은 데이터의 단기적 변동을 평탄화하여 보여줍니다. rolling() 함수에서 center=True 옵션을 사용하면 이동 평균 계산 시 윈도우의 중앙에 값을 위치시켜 시각화 시 원본 데이터와의 지연(lag)을 줄이는 데 도움이 됩니다.\n두 번째 그래프는 원본 데이터와 이동 평균과의 편차를 보여줍니다. 이 편차가 특정 임계값(예: 편차의 3 표준편차, ±3σ)을 넘어서는 지점들은 잠재적인 이상치로 간주할 수 있습니다. 우리가 삽입한 인위적인 스파이크와 급감 지점에서 편차가 크게 나타나는 것을 확인할 수 있습니다. 이러한 방법은 간단하면서도 효과적인 이상치 탐색의 기초가 됩니다."
  },
  {
    "objectID": "posts/ABC_week01_data analysis/index.html#요약",
    "href": "posts/ABC_week01_data analysis/index.html#요약",
    "title": "[2025 ABC 프로젝트 멘토링 8기] 1주차 - 시계열 이상 탐지를 위한 EDA 및 전처리",
    "section": "요약",
    "text": "요약\n이 포스트에서는 Python을 사용하여 가상의 산업 전력 사용량 데이터를 생성하고, 이상 탐지를 위한 기본적인 탐색적 데이터 분석(EDA) 및 전처리 과정을 살펴보았습니다. 시계열 플롯, 분포 확인, 주기성 분석(요일별 Box Plot), 이동 평균 활용 등은 데이터의 특성을 이해하고 잠재적인 이상치를 식별하는 데 효과적인 방법입니다."
  },
  {
    "objectID": "posts/ABC_week03_cnn_baseline/index.html",
    "href": "posts/ABC_week03_cnn_baseline/index.html",
    "title": "[2025 ABC 프로젝트 멘토링 8기] 3주차 - CNN으로 시계열 이상 탐지 (PyTorch)",
    "section": "",
    "text": "안녕하세요, ABC 프로젝트 멘토링 8기 세 번째 기술노트입니다. 이번 주는 시계열 데이터의 ’패턴’을 학습할 수 있는 딥러닝, 그중에서도 CNN을 활용한 이상 탐지의 첫걸음을 PyTorch로 구현해 보겠습니다."
  },
  {
    "objectID": "posts/ABC_week03_cnn_baseline/index.html#시계열-데이터를-cnn에-입력하는-방법-윈도잉windowing",
    "href": "posts/ABC_week03_cnn_baseline/index.html#시계열-데이터를-cnn에-입력하는-방법-윈도잉windowing",
    "title": "[2025 ABC 프로젝트 멘토링 8기] 3주차 - CNN으로 시계열 이상 탐지 (PyTorch)",
    "section": "1. 시계열 데이터를 CNN에 입력하는 방법: 윈도잉(Windowing)",
    "text": "1. 시계열 데이터를 CNN에 입력하는 방법: 윈도잉(Windowing)\n시계열 데이터를 CNN 모델에 입력하려면 연속된 데이터를 일정한 길이의 조각(window)으로 나누는 ‘슬라이딩 윈도우’ 기법이 필요합니다. 이 방법은 데이터의 시간적 패턴을 학습하는 데 유용합니다.\n\n슬라이딩 윈도우 구현\n아래는 numpy를 사용해 슬라이딩 윈도우를 구현하는 간단한 Python 함수입니다:\n\nimport numpy as np\n\ndef sliding_window(data, window_size, step_size=1):\n    \"\"\"시계열 데이터를 슬라이딩 윈도우로 변환\"\"\"\n    n_windows = (len(data) - window_size) // step_size + 1\n    return np.array([data[i:i+window_size] for i in range(0, n_windows * step_size, step_size)])\n\n# 예제 데이터\ndata = np.sin(np.linspace(0, 20, 100))\nwindowed_data = sliding_window(data, window_size=10)\nprint(\"윈도우 형태:\", windowed_data.shape)\n\n윈도우 형태: (91, 10)"
  },
  {
    "objectID": "posts/ABC_week03_cnn_baseline/index.html#기본-이상-탐지-모델-cnn-오토인코더-autoencoder",
    "href": "posts/ABC_week03_cnn_baseline/index.html#기본-이상-탐지-모델-cnn-오토인코더-autoencoder",
    "title": "[2025 ABC 프로젝트 멘토링 8기] 3주차 - CNN으로 시계열 이상 탐지 (PyTorch)",
    "section": "2. 기본 이상 탐지 모델: CNN 오토인코더 (Autoencoder)",
    "text": "2. 기본 이상 탐지 모델: CNN 오토인코더 (Autoencoder)\n\n오토인코더란?\n오토인코더는 데이터를 압축(인코더)했다가 다시 복원(디코더)하도록 학습하는 딥러닝 모델입니다. 정상 데이터는 잘 복원되지만, 이상 데이터는 복원이 잘 되지 않아 재구성 오차가 커지는 특징을 활용합니다.\n\n\n모델 구조\n\n인코더 (Encoder): Conv1D와 MaxPooling1D 층을 사용해 입력 데이터의 특징을 추출하고 압축합니다.\n디코더 (Decoder): ConvTranspose1D (또는 Upsample + Conv1D) 층을 사용해 데이터를 복원합니다.\n\n\n\nPyTorch 구현\n아래는 PyTorch를 사용한 간단한 1D CNN 오토인코더 모델 구현입니다:\n\nimport torch\nimport torch.nn as nn\n\nclass CNNAutoencoder(nn.Module):\n    def __init__(self, input_shape): # input_shape: (sequence_length, num_features)\n        super(CNNAutoencoder, self).__init__()\n        # Encoder\n        # input_shape[1]은 특성 수 (in_channels로 사용)\n        self.encoder_conv1 = nn.Conv1d(in_channels=input_shape[1], out_channels=32, kernel_size=3, padding=1)\n        self.encoder_relu1 = nn.ReLU()\n        self.encoder_pool1 = nn.MaxPool1d(kernel_size=2, stride=2) # 시퀀스 길이 1/2로 감소\n        self.encoder_conv2 = nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n        self.encoder_relu2 = nn.ReLU()\n        self.encoder_pool2 = nn.MaxPool1d(kernel_size=2, stride=2) # 시퀀스 길이 1/4로 감소\n\n        # Decoder\n        # 인코더에서 시퀀스 길이가 1/4로 줄었으므로, 디코더에서 원래 길이로 복원\n        self.decoder_conv_t1 = nn.ConvTranspose1d(in_channels=16, out_channels=16, kernel_size=4, stride=2, padding=1, output_padding=1)\n        self.decoder_relu1 = nn.ReLU()\n        self.decoder_conv_t2 = nn.ConvTranspose1d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1, output_padding=1)\n        self.decoder_relu2 = nn.ReLU()\n        self.decoder_conv_final = nn.Conv1d(in_channels=32, out_channels=input_shape[1], kernel_size=3, padding=1) # 원본 특성 수로 복원\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        # Encoder\n        x = self.encoder_conv1(x)\n        x = self.encoder_relu1(x)\n        x = self.encoder_pool1(x)\n        x = self.encoder_conv2(x)\n        x = self.encoder_relu2(x)\n        encoded = self.encoder_pool2(x)\n        \n        # Decoder\n        x = self.decoder_conv_t1(encoded)\n        x = self.decoder_relu1(x)\n        x = self.decoder_conv_t2(x)\n        x = self.decoder_relu2(x)\n        x = self.decoder_conv_final(x)\n        decoded = self.sigmoid(x)\n        return decoded\n\n# 모델 생성 및 컴파일은 data-generation 셀 이후로 이동합니다.\n# input_shape도 window_size를 사용하도록 수정됩니다."
  },
  {
    "objectID": "posts/ABC_week03_cnn_baseline/index.html#모델-학습-및-이상치-탐지",
    "href": "posts/ABC_week03_cnn_baseline/index.html#모델-학습-및-이상치-탐지",
    "title": "[2025 ABC 프로젝트 멘토링 8기] 3주차 - CNN으로 시계열 이상 탐지 (PyTorch)",
    "section": "3. 모델 학습 및 이상치 탐지",
    "text": "3. 모델 학습 및 이상치 탐지\n\n데이터 생성\nWeek2에서 사용한 샘플 데이터를 기반으로 정상/비정상 데이터를 생성합니다:\n\n# numpy는 sliding_window_implementation 셀에서 이미 import 됨\n\n# 데이터 생성\nnp.random.seed(42)\ndata = np.sin(0.2 * np.arange(0, 100)) + np.random.normal(0, 0.1, 100)\noutliers = [20, 50, 80]\ndata[outliers] += [3, -3, 2]\n\n# 슬라이딩 윈도우 적용\nwindow_size = 10\nwindows = sliding_window(data, window_size) # (N, L) -&gt; (N, window_size)\nwindows = windows[..., np.newaxis]  # (N, L, C) -&gt; (N, window_size, 1)\n# PyTorch Conv1d는 (N, C, L) 입력을 기대하므로 차원 변경\nwindows = windows.transpose(0, 2, 1) # (N, C, L) -&gt; (N, 1, window_size)\nprint(f\"윈도우 데이터 형태 (N, C, L): {windows.shape}\")\n\n윈도우 데이터 형태 (N, C, L): (91, 1, 10)\n\n\n\nimport torch.optim as optim # PyTorch 옵티마이저\n\n# 모델 생성\n# input_shape은 (window_size, 1) 이어야 합니다. (sequence_length, num_features)\n# data-generation 셀에서 windows는 (N, 1, window_size) 형태로 준비됨.\n# CNNAutoencoder의 __init__은 input_shape=(window_size, 1)을 받아 input_shape[1]=1을 in_channels로 사용.\nmodel_input_shape = (window_size, 1) # (sequence_length, num_features)\nmodel = CNNAutoencoder(model_input_shape) # cnn-autoencoder-definition 셀에서 정의된 클래스 사용\n\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.MSELoss() # 평균 제곱 오차 손실\n\nprint(\"PyTorch 모델 구조:\")\nprint(model)\n\nPyTorch 모델 구조:\nCNNAutoencoder(\n  (encoder_conv1): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n  (encoder_relu1): ReLU()\n  (encoder_pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (encoder_conv2): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n  (encoder_relu2): ReLU()\n  (encoder_pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (decoder_conv_t1): ConvTranspose1d(16, 16, kernel_size=(4,), stride=(2,), padding=(1,), output_padding=(1,))\n  (decoder_relu1): ReLU()\n  (decoder_conv_t2): ConvTranspose1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n  (decoder_relu2): ReLU()\n  (decoder_conv_final): Conv1d(32, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n  (sigmoid): Sigmoid()\n)\n\n\n\n\n모델 학습\n정상 데이터만 사용해 모델을 학습합니다:\n\n# torch는 cnn-autoencoder-definition 셀에서 이미 import 됨\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# 정상 데이터로 학습\n# 'outliers'는 원본 'data' 배열의 인덱스입니다.\n# 'windows' 배열에서 이상치가 포함된 윈도우를 식별하여 제외합니다.\ncontaminated_window_indices = set()\n# 'outliers', 'window_size', 'windows' 변수는 이전 셀들에서 정의되어 있어야 합니다.\nfor outlier_data_idx in outliers: \n    start_contaminated_win_idx = max(0, outlier_data_idx - window_size + 1)\n    end_contaminated_win_idx = outlier_data_idx \n    \n    for win_idx in range(start_contaminated_win_idx, end_contaminated_win_idx + 1):\n        if win_idx &lt; len(windows): # 윈도우 인덱스가 유효한 범위 내에 있는지 확인\n            contaminated_window_indices.add(win_idx)\n\nnormal_windows_mask = np.ones(len(windows), dtype=bool)\nif contaminated_window_indices: # set이 비어있지 않은 경우에만 인덱싱\n    normal_windows_mask[list(contaminated_window_indices)] = False\n\nnormal_windows_np = windows[normal_windows_mask]\n\nif len(normal_windows_np) == 0:\n    print(\"경고: 학습에 사용할 정상 윈도우가 없습니다. Outlier 정의, window_size 또는 데이터 길이를 확인하세요.\")\nelse:\n    # PyTorch 데이터셋 및 로더 준비\n    normal_windows_torch = torch.tensor(normal_windows_np, dtype=torch.float32)\n    train_dataset = TensorDataset(normal_windows_torch) # 오토인코더는 입력과 타겟이 동일\n    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\n    # 모델 학습\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n    model.to(device)\n    \n    epochs = 50 # 에포크 수 설정\n    print_every_epochs = 10\n\n    model.train() # 학습 모드\n    for epoch in range(epochs):\n        epoch_loss = 0\n        for batch_data_list in train_loader:\n            inputs = batch_data_list[0].to(device)\n            targets = inputs # 오토인코더의 타겟은 입력과 동일\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            \n            epoch_loss += loss.item() * inputs.size(0) # 배치 손실 누적 (loss.item()은 평균 손실)\n        \n        epoch_loss /= len(train_loader.dataset) # 에포크 평균 손실\n        if (epoch + 1) % print_every_epochs == 0:\n            print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.6f}\")\n    print(\"모델 학습 완료.\")\n\nUsing device: cuda\nEpoch [10/50], Loss: 0.373374\nEpoch [20/50], Loss: 0.269607\nEpoch [30/50], Loss: 0.233523\nEpoch [40/50], Loss: 0.219008\nEpoch [50/50], Loss: 0.210084\n모델 학습 완료.\n\n\n\n\n재구성 오차 계산 및 이상치 탐지\n학습된 모델로 데이터를 복원하고, 재구성 오차를 계산합니다:\n\n# torch 및 numpy는 이전 셀들에서 이미 import 됨\n\n# 재구성 오차 계산\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval() # 평가 모드\n\n# 전체 windows 데이터를 PyTorch 텐서로 변환하고 device로 이동\nall_windows_torch = torch.tensor(windows, dtype=torch.float32).to(device)\n\n# 메모리 부족을 방지하기 위해 배치 단위로 처리할 수 있으나, 현재 데이터는 작으므로 한번에 처리\nwith torch.no_grad(): # 그래디언트 계산 비활성화\n    reconstructed_torch = model(all_windows_torch)\n\n# 결과를 CPU로 옮기고 NumPy 배열로 변환\nreconstructed_np = reconstructed_torch.cpu().numpy()\n\n# MAE (Mean Absolute Error) 계산\n# 원본 windows (numpy 배열)와 reconstructed_np 모두 (N, 1, window_size) 형태\n# axis=(1, 2)는 채널과 시퀀스 길이에 대한 평균을 의미\nmae = np.mean(np.abs(windows - reconstructed_np), axis=(1, 2))\nprint(f\"계산된 MAE 값 (처음 5개): {mae[:5]}\")\n\n# 이상치 탐지를 위한 임계값 설정 (데이터 및 모델 성능에 따라 조정 필요)\n# 예: MAE의 평균 + (표준편차 * 특정 배수) 또는 분위수 사용\nthreshold = np.mean(mae) + 1.5 * np.std(mae) # 표준편차 배수를 2에서 1.5로 줄여 민감도 증가\nprint(f\"이상치 탐지 임계값 (MAE): {threshold:.4f}\")\n\nanomalies_indices_in_windows = np.where(mae &gt; threshold)[0] # 윈도우 배열 내의 인덱스\n\nprint(f\"이상치로 탐지된 윈도우의 수: {len(anomalies_indices_in_windows)}\")\nprint(f\"이상치로 탐지된 윈도우 인덱스: {anomalies_indices_in_windows}\")\n\n# 윈도우 인덱스를 원본 데이터 인덱스로 대략적으로 매핑 (윈도우의 시작점 기준)\n# 실제 이상치 발생 시점과 정확히 일치하지 않을 수 있음\nanomalies_approx_original_indices = anomalies_indices_in_windows \n# 좀 더 정확하게는 윈도우의 중간 지점 등을 고려할 수 있으나, 여기서는 시작점으로 단순화\n# anomalies_approx_original_indices = [idx + window_size // 2 for idx in anomalies_indices_in_windows]\nprint(f\"원본 데이터의 대략적인 이상치 인덱스 (윈도우 시작점 기준): {anomalies_approx_original_indices}\")\n\n계산된 MAE 값 (처음 5개): [0.13334458 0.1224654  0.08777217 0.06363949 0.08642011]\n이상치 탐지 임계값 (MAE): 0.9535\n이상치로 탐지된 윈도우의 수: 8\n이상치로 탐지된 윈도우 인덱스: [17 18 19 20 47 48 49 50]\n원본 데이터의 대략적인 이상치 인덱스 (윈도우 시작점 기준): [17 18 19 20 47 48 49 50]\n\n\n\n\n결과 시각화\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 4))\nplt.plot(data, label='원본 데이터', alpha=0.7) # 'data'는 data-generation에서 정의됨\nplt.scatter(outliers, data[outliers], color='red', s=100, label='실제 이상치 (Ground Truth)', marker='o', edgecolors='black') # 'outliers'는 data-generation에서 정의됨\n\n# anomalies_approx_original_indices가 비어있을 수 있으므로 확인\nif len(anomalies_approx_original_indices) &gt; 0:\n    # 탐지된 이상치 표시는 윈도우의 시작점을 기준으로 함\n    plt.scatter(anomalies_approx_original_indices, data[anomalies_approx_original_indices], \n                color='orange', marker='x', s=80, label='탐지된 이상치 (모델 예측)', alpha=0.8)\nelse:\n    print(\"탐지된 이상치가 없습니다.\")\n        \nplt.legend()\nplt.title('PyTorch CNN 오토인코더 기반 시계열 이상 탐지')\nplt.xlabel('시간 스텝')\nplt.ylabel('값')\nplt.grid(True, linestyle='--', alpha=0.6)\nplt.show()\n\n# 재구성 오차(MAE) 시각화\nplt.figure(figsize=(10, 3))\nplt.plot(mae, label='재구성 오차 (MAE)', color='green')\nplt.axhline(threshold, color='red', linestyle='--', label=f'임계값 ({threshold:.2f})')\nplt.title('윈도우별 재구성 오차 (MAE) 및 임계값')\nplt.xlabel('윈도우 인덱스')\nplt.ylabel('MAE')\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.6)\nplt.show()\n\n\n\n\nPyTorch CNN 오토인코더 기반 이상 탐지 결과\n\n\n\n\n\n\n\n\n\n\n\n\n\n탐지 결과에 대한 심층 분석 및 고려사항\n위 시각화 결과와 재구성 오차를 살펴보면 몇 가지 고려할 점이 있습니다.\n\n실제 이상치와 탐지된 이상치: data-generation에서 의도적으로 삽입한 실제 이상치(outliers = [20, 50, 80])와 모델이 탐지한 이상치를 비교해 보면, 모든 실제 이상치가 탐지되지 않았을 수도 있고, 반대로 정상적인 구간이 이상치로 탐지되었을 수도 있습니다. 현재 예제에서는 임계값(np.mean(mae) + 1.5 * np.std(mae)) 조정으로 최소 하나의 이상치를 탐지하도록 유도했지만, 실제 상황에서는 모델 성능, 데이터 특성, window_size 및 임계값 설정에 따라 결과가 크게 달라집니다.\n윈도우 경계 효과 (Edge Effects): 시계열 데이터의 처음과 끝 부분에서 생성된 윈도우들은 내부 윈도우에 비해 불완전한 정보를 가질 수 있습니다. 예를 들어, 첫 번째 윈도우는 이전 시점의 데이터가 없고, 마지막 윈도우는 이후 시점의 데이터가 없습니다. CNN 모델, 특히 패딩을 사용하는 경우, 이러한 경계 영역의 윈도우들은 모델이 학습한 주요 정상 패턴과 달라 재구성 오차가 상대적으로 크게 나타날 수 있습니다. 이로 인해 시계열의 양 끝부분에서 이상치가 아닌데도 이상치로 탐지되는 경향이 나타날 수 있습니다. 위 MAE 그래프에서 초반 또는 후반부에 높은 오차가 관찰된다면 이러한 경계 효과를 의심해 볼 수 있습니다.\nwindow_size의 중요성: window_size는 모델이 학습할 패턴의 길이를 결정합니다. window_size가 너무 작으면 장기적인 패턴을 파악하기 어렵고, 너무 크면 짧은 순간의 이상치를 놓치거나 정상적인 변동에도 민감하게 반응할 수 있습니다. 현재 window_size=10으로 설정되어 있는데, 데이터의 특성에 따라 이 값을 조정하며 실험해 보는 것이 중요합니다.\n모델 및 임계값의 한계: 현재 사용된 CNN 오토인코더는 비교적 간단한 모델입니다. 더 복잡한 패턴이나 다양한 유형의 이상치를 탐지하기 위해서는 모델 구조를 개선하거나 (예: LSTM, Transformer 기반 오토인코더), 다른 접근 방식을 고려해야 할 수 있습니다. 또한, 고정된 임계값 대신 동적 임계값을 사용하거나, 통계적 검정 기법을 결합하는 것도 탐지 성능을 높이는 데 도움이 될 수 있습니다.\n\n이러한 점들을 고려하여 모델의 결과를 해석하고, 실제 문제에 적용할 때는 충분한 검증과 실험이 필요합니다."
  },
  {
    "objectID": "posts/ABC_week03_cnn_baseline/index.html#결론-및-다음-단계",
    "href": "posts/ABC_week03_cnn_baseline/index.html#결론-및-다음-단계",
    "title": "[2025 ABC 프로젝트 멘토링 8기] 3주차 - CNN으로 시계열 이상 탐지 (PyTorch)",
    "section": "결론 및 다음 단계",
    "text": "결론 및 다음 단계\n이번 주에는 PyTorch를 사용하여 간단한 1D CNN 오토인코더를 설계하고, 이를 활용해 시계열 데이터의 이상 탐지를 수행했습니다. 이 모델은 시계열 이상 탐지의 강력한 베이스라인이 될 수 있습니다. 재구성 오차를 기반으로 이상치를 탐지하는 과정을 확인했으며, 임계값 설정 방법에 따라 탐지 결과가 달라질 수 있음을 알 수 있습니다.\n다음 포스트에서는 실제 산업 데이터를 사용해 모델을 학습시키고, 성능을 개선하기 위한 다양한 방법 (예: 더 복잡한 모델 구조, 다른 유형의 오토인코더, 동적 임계값 설정 등)을 탐구해 보겠습니다."
  }
]