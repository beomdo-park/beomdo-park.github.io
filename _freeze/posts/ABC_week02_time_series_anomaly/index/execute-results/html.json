{
  "hash": "705c96124a4a8b337b28b3506d4fcc47",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"[2025 ABC 프로젝트 멘토링 8기] 2주차 - 시계열 이상 탐지와 머신러닝 기초 적용\"\ndescription: \"Python을 활용한 시계열 데이터 이상 탐지 - 머신러닝 기법 적용 실습\"\ndate: \"2025-06-01\"\nauthor: \"Beomdo Park\"\ncategories: [\"ABC프로젝트멘토링\", \"유클리드소프트\", \"고용노동부\", \"대한상공회의소\", \"미래내일일경험사업\"]\npage-layout: full\nfreeze: true\n---\n\n> 안녕하세요 이번 포스트는 [ABC 프로젝트 멘토링](https://abcbootcamp.kr/abc_mentor/) 8기 2주차 실습 기록입니다.\n지난주엔 시계열 데이터 EDA랑 전처리만 했는데, 이번엔 간단한 머신러닝 모델로 이상치 탐지 기법을 소개하려 합니다.  \n\n::: {.callout-tip title=\"\"}\n이 포스트는 [week01](https://beomdo-park.github.io/posts/ABC_week01_data%20analysis/)에서 진행했던 데이터 준비/탐색 내용을 바탕으로, 실제 머신러닝 기반 이상 탐지 실습에 초점을 맞췄습니다.\n:::\n\n## 1. 데이터 준비\n\n\n::: {#load-libraries .cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import IsolationForest\nimport warnings\nwarnings.filterwarnings('ignore')\n```\n:::\n\n\n::: {#generate-sample-data .cell execution_count=3}\n``` {.python .cell-code}\nnp.random.seed(42)\nt = np.arange(0, 100, 1)\ny = np.sin(0.2 * t) + np.random.normal(0, 0.2, size=len(t))\n# 여러 위치에 인위적으로 이상치 추가\noutlier_indices = [15, 35, 55, 75, 90]\noutlier_values = [2, -2, 2.5, -2.5, 3]\nfor idx, val in zip(outlier_indices, outlier_values):\n    y[idx] += val\ndf = pd.DataFrame({'time': t, 'value': y})\n```\n:::\n\n\n::: {#cell-plot-sample-data .cell execution_count=4}\n``` {.python .cell-code}\nplt.figure(figsize=(10,4))\nplt.plot(df['time'], df['value'], label='시계열 데이터')\nplt.scatter(df.loc[outlier_indices, 'time'], df.loc[outlier_indices, 'value'], color='red', label='부여한 이상값')\nplt.legend()\nplt.title('이상값이 포함된 시계열 데이터')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![이상값이 포함된 시계열 데이터](index_files/figure-html/plot-sample-data-output-1.png){#plot-sample-data width=826 height=370}\n:::\n:::\n\n\n## 2. 머신러닝 기반 이상 탐지 (Isolation Forest, DBSCAN, One-Class SVM)\n\n### 모델별 특징 및 한계\n\n| 모델              | 장점                                      | 한계/주의점                          |\n|-------------------|------------------------------------------|--------------------------------------|\n| Isolation Forest  | 대용량/고차원 데이터에 강함, 빠름         | 이상치 비율(contamination) 추정 필요  |\n| DBSCAN            | 군집/밀도 기반, 파라미터 직관적           | eps, min_samples에 민감, 1차원 한계   |\n| One-Class SVM     | 비선형 경계, 소규모 데이터에 적합         | 느릴 수 있음, 파라미터 튜닝 필요      |\n\n### Isolation Forest\n\n::: {#fit-isolation-forest .cell execution_count=5}\n``` {.python .cell-code}\nfrom sklearn.ensemble import IsolationForest\nmodel = IsolationForest(contamination=0.05, random_state=42)\ndf['anomaly_isof'] = model.fit_predict(df[['value']])\n```\n:::\n\n\n::: {#cell-plot-anomaly-isof .cell execution_count=6}\n``` {.python .cell-code}\nplt.figure(figsize=(10,4))\nplt.plot(df['time'], df['value'], label='시계열 데이터')\nplt.scatter(df[df['anomaly_isof']==-1]['time'], df[df['anomaly_isof']==-1]['value'], color='red', label='탐지된 이상값')\nplt.legend()\nplt.title('Isolation Forest 기반 이상 탐지 결과')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Isolation Forest 기반 이상 탐지 결과](index_files/figure-html/plot-anomaly-isof-output-1.png){#plot-anomaly-isof width=826 height=370}\n:::\n:::\n\n\n### DBSCAN (밀도 기반 이상 탐지)\n\n::: {#fit-dbscan .cell execution_count=7}\n``` {.python .cell-code}\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(df[['value']])\ndbscan = DBSCAN(eps=0.25, min_samples=3)  # eps와 min_samples를 조정해 민감도 조정\ndf['anomaly_dbscan'] = dbscan.fit_predict(X_scaled)\n```\n:::\n\n\n::: {#cell-plot-anomaly-dbscan .cell execution_count=8}\n``` {.python .cell-code}\nplt.figure(figsize=(10,4))\nplt.plot(df['time'], df['value'], label='시계열 데이터')\nplt.scatter(df[df['anomaly_dbscan']==-1]['time'], df[df['anomaly_dbscan']==-1]['value'], color='orange', label='탐지된 이상값(DBSCAN)')\nplt.legend()\nplt.title('DBSCAN 기반 이상 탐지 결과')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![DBSCAN 기반 이상 탐지 결과](index_files/figure-html/plot-anomaly-dbscan-output-1.png){#plot-anomaly-dbscan width=826 height=370}\n:::\n:::\n\n\n### One-Class SVM (서포트 벡터 머신 기반 이상 탐지)\n\n::: {#fit-ocsvm .cell execution_count=9}\n``` {.python .cell-code}\nfrom sklearn.svm import OneClassSVM\n# 기본 파라미터로는 이상치 탐지가 잘 안 됨 (F1이 0.14 수준)\nocsvm = OneClassSVM(nu=0.05, kernel='rbf', gamma='auto')\ndf['anomaly_ocsvm'] = ocsvm.fit_predict(df[['value']])\n```\n:::\n\n\n::: {#cell-plot-anomaly-ocsvm .cell execution_count=10}\n``` {.python .cell-code}\nplt.figure(figsize=(10,4))\nplt.plot(df['time'], df['value'], label='시계열 데이터')\nplt.scatter(df[df['anomaly_ocsvm']==-1]['time'], df[df['anomaly_ocsvm']==-1]['value'], color='purple', label='탐지된 이상값(OCSVM)')\nplt.legend()\nplt.title('One-Class SVM 기반 이상 탐지 결과')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![One-Class SVM 기반 이상 탐지 결과](index_files/figure-html/plot-anomaly-ocsvm-output-1.png){#plot-anomaly-ocsvm width=826 height=370}\n:::\n:::\n\n\n#### SVM 파라미터 튜닝 시도\n\n::: {#fit-ocsvm-tuned .cell execution_count=11}\n``` {.python .cell-code}\n# gamma 값을 더 크게, nu 값을 더 높게 조정해서 민감도를 높임\nocsvm_tuned = OneClassSVM(nu=0.12, kernel='rbf', gamma=2)\ndf['anomaly_ocsvm_tuned'] = ocsvm_tuned.fit_predict(df[['value']])\n```\n:::\n\n\n::: {#cell-plot-anomaly-ocsvm-tuned .cell execution_count=12}\n``` {.python .cell-code}\nplt.figure(figsize=(10,4))\nplt.plot(df['time'], df['value'], label='시계열 데이터')\nplt.scatter(df[df['anomaly_ocsvm_tuned']==-1]['time'], df[df['anomaly_ocsvm_tuned']==-1]['value'], color='blue', label='탐지된 이상값(튜닝 SVM)')\nplt.legend()\nplt.title('튜닝된 One-Class SVM 기반 이상 탐지 결과')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![튜닝된 One-Class SVM 이상 탐지 결과](index_files/figure-html/plot-anomaly-ocsvm-tuned-output-1.png){#plot-anomaly-ocsvm-tuned width=826 height=370}\n:::\n:::\n\n\n### 이상치 탐지 및 평가지표(Precision, Recall, F1)\n\n::: {#anomaly-metrics .cell execution_count=13}\n``` {.python .cell-code}\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\ndef anomaly_metrics(true_outliers, pred_outliers, n):\n    true = [1 if i in true_outliers else 0 for i in range(n)]\n    pred = [1 if i in pred_outliers else 0 for i in range(n)]\n    p = precision_score(true, pred)\n    r = recall_score(true, pred)\n    f1 = f1_score(true, pred)\n    return p, r, f1\n\nn = len(df)\ntrue_outliers = outlier_indices\npred_isof = df.index[df['anomaly_isof']==-1].tolist()\np_isof, r_isof, f1_isof = anomaly_metrics(true_outliers, pred_isof, n)\npred_dbscan = df.index[df['anomaly_dbscan']==-1].tolist()\np_dbscan, r_dbscan, f1_dbscan = anomaly_metrics(true_outliers, pred_dbscan, n)\npred_ocsvm = df.index[df['anomaly_ocsvm']==-1].tolist()\np_ocsvm, r_ocsvm, f1_ocsvm = anomaly_metrics(true_outliers, pred_ocsvm, n)\npred_ocsvm_tuned = df.index[df['anomaly_ocsvm_tuned']==-1].tolist()\np_ocsvm_t, r_ocsvm_t, f1_ocsvm_t = anomaly_metrics(true_outliers, pred_ocsvm_tuned, n)\n\nprint(f\"Isolation Forest - Precision: {p_isof:.2f}, Recall: {r_isof:.2f}, F1: {f1_isof:.2f}\")\nprint(f\"DBSCAN           - Precision: {p_dbscan:.2f}, Recall: {r_dbscan:.2f}, F1: {f1_dbscan:.2f}\")\nprint(f\"One-Class SVM    - Precision: {p_ocsvm:.2f}, Recall: {r_ocsvm:.2f}, F1: {f1_ocsvm:.2f}\")\nprint(f\"튜닝 SVM         - Precision: {p_ocsvm_t:.2f}, Recall: {r_ocsvm_t:.2f}, F1: {f1_ocsvm_t:.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIsolation Forest - Precision: 1.00, Recall: 1.00, F1: 1.00\nDBSCAN           - Precision: 1.00, Recall: 1.00, F1: 1.00\nOne-Class SVM    - Precision: 0.14, Recall: 0.40, F1: 0.21\n튜닝 SVM         - Precision: 0.21, Recall: 1.00, F1: 0.34\n```\n:::\n:::\n\n\n## 3. 결과 해석 및 정리\n\n- One-Class SVM은 기본 파라미터로는 이상치 탐지가 잘 되지 않았으나, gamma와 nu를 조정해 튜닝하면 성능이 개선되는 것을 확인할 수 있다. 이 과정에서 파라미터 튜닝의 중요성을 경험했다.\n- 각 모델별로 이상치 탐지 결과와 평가지표(Precision, Recall, F1)가 다르게 나타난다. Isolation Forest는 인위적으로 넣은 이상치를 대부분 탐지했고, DBSCAN은 파라미터에 따라 민감하게 반응한다. One-Class SVM은 데이터 분포와 파라미터에 따라 결과가 크게 달라진다.\n- Precision(정밀도), Recall(재현율), F1-score는 모델의 이상치 탐지 성능을 종합적으로 평가하는 지표로, 실제 데이터 분석에서는 여러 방법을 비교하고 도메인 지식과 함께 해석하는 것이 중요하다.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}