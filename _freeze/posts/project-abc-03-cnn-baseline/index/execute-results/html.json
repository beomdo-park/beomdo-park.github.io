{
  "hash": "8a49135fc490abc33cc0aff2089d4750",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"[2025 ABC 프로젝트 멘토링 8기] 3주차 - CNN으로 시계열 이상 탐지 (PyTorch)\"\ndescription: \"PyTorch를 사용하여 1D CNN 오토인코더 기반 시계열 이상 탐지 베이스라인 모델을 구현합니다.\"\ndate: 2025-06-08\nauthor: \"Beomdo Park\"\ncategories: [\"ABC프로젝트멘토링\", \"PyTorch\"]\ntags: [\"CNN\", \"오토인코더\", \"PyTorch\", \"시계열이상탐지\"]\npage-layout: full\nfreeze: true\n---\n\n> 안녕하세요, ABC 프로젝트 멘토링 8기 세 번째 기술노트입니다. 이번 주는 시계열 데이터의 '패턴'을 학습할 수 있는 딥러닝, 그중에서도 CNN을 활용한 이상 탐지의 첫걸음을 PyTorch로 구현해 보겠습니다.\n\n::: {.callout-tip title=\"이전 포스트\"}\n[Week2 포스트](/posts/project-abc-02-time-series-anomaly/)에서 머신러닝 기반 이상 탐지 기법을 다뤘습니다. 이번 포스트는 이를 기반으로 PyTorch를 사용한 딥러닝 접근법을 소개합니다.\n:::\n\n\n## 1. 시계열 데이터를 CNN에 입력하는 방법: 윈도잉(Windowing)\n\n시계열 데이터를 CNN 모델에 입력하려면 연속된 데이터를 일정한 길이의 조각(window)으로 나누는 '슬라이딩 윈도우' 기법이 필요합니다. 이 방법은 데이터의 시간적 패턴을 학습하는 데 유용합니다.\n\n### 슬라이딩 윈도우 구현\n\n아래는 numpy를 사용해 슬라이딩 윈도우를 구현하는 간단한 Python 함수입니다:\n\n::: {#sliding-window-implementation .cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\n\ndef sliding_window(data, window_size, step_size=1):\n    \"\"\"시계열 데이터를 슬라이딩 윈도우로 변환\"\"\"\n    n_windows = (len(data) - window_size) // step_size + 1\n    return np.array([data[i:i+window_size] for i in range(0, n_windows * step_size, step_size)])\n\n# 예제 데이터\ndata = np.sin(np.linspace(0, 20, 100))\nwindowed_data = sliding_window(data, window_size=10)\nprint(\"윈도우 형태:\", windowed_data.shape)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n윈도우 형태: (91, 10)\n```\n:::\n:::\n\n\n## 2. 기본 이상 탐지 모델: CNN 오토인코더 (Autoencoder)\n\n### 오토인코더란?\n오토인코더는 데이터를 압축(인코더)했다가 다시 복원(디코더)하도록 학습하는 딥러닝 모델입니다. 정상 데이터는 잘 복원되지만, 이상 데이터는 복원이 잘 되지 않아 재구성 오차가 커지는 특징을 활용합니다.\n\n### 모델 구조\n\n- **인코더 (Encoder):** Conv1D와 MaxPooling1D 층을 사용해 입력 데이터의 특징을 추출하고 압축합니다.\n- **디코더 (Decoder):** ConvTranspose1D (또는 Upsample + Conv1D) 층을 사용해 데이터를 복원합니다.\n\n### PyTorch 구현\n\n아래는 PyTorch를 사용한 간단한 1D CNN 오토인코더 모델 구현입니다:\n\n::: {#cnn-autoencoder-definition .cell execution_count=3}\n``` {.python .cell-code}\nimport torch\nimport torch.nn as nn\n\nclass CNNAutoencoder(nn.Module):\n    def __init__(self, input_shape): # input_shape: (sequence_length, num_features)\n        super(CNNAutoencoder, self).__init__()\n        # Encoder\n        # input_shape[1]은 특성 수 (in_channels로 사용)\n        self.encoder_conv1 = nn.Conv1d(in_channels=input_shape[1], out_channels=32, kernel_size=3, padding=1)\n        self.encoder_relu1 = nn.ReLU()\n        self.encoder_pool1 = nn.MaxPool1d(kernel_size=2, stride=2) # 시퀀스 길이 1/2로 감소\n        self.encoder_conv2 = nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n        self.encoder_relu2 = nn.ReLU()\n        self.encoder_pool2 = nn.MaxPool1d(kernel_size=2, stride=2) # 시퀀스 길이 1/4로 감소\n\n        # Decoder\n        # 인코더에서 시퀀스 길이가 1/4로 줄었으므로, 디코더에서 원래 길이로 복원\n        self.decoder_conv_t1 = nn.ConvTranspose1d(in_channels=16, out_channels=16, kernel_size=4, stride=2, padding=1, output_padding=1)\n        self.decoder_relu1 = nn.ReLU()\n        self.decoder_conv_t2 = nn.ConvTranspose1d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1, output_padding=1)\n        self.decoder_relu2 = nn.ReLU()\n        self.decoder_conv_final = nn.Conv1d(in_channels=32, out_channels=input_shape[1], kernel_size=3, padding=1) # 원본 특성 수로 복원\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        # Encoder\n        x = self.encoder_conv1(x)\n        x = self.encoder_relu1(x)\n        x = self.encoder_pool1(x)\n        x = self.encoder_conv2(x)\n        x = self.encoder_relu2(x)\n        encoded = self.encoder_pool2(x)\n        \n        # Decoder\n        x = self.decoder_conv_t1(encoded)\n        x = self.decoder_relu1(x)\n        x = self.decoder_conv_t2(x)\n        x = self.decoder_relu2(x)\n        x = self.decoder_conv_final(x)\n        decoded = self.sigmoid(x)\n        return decoded\n\n# 모델 생성 및 컴파일은 data-generation 셀 이후로 이동합니다.\n# input_shape도 window_size를 사용하도록 수정됩니다.\n```\n:::\n\n\n## 3. 모델 학습 및 이상치 탐지\n\n### 데이터 생성\n\nWeek2에서 사용한 샘플 데이터를 기반으로 정상/비정상 데이터를 생성합니다:\n\n::: {#data-generation .cell execution_count=4}\n``` {.python .cell-code}\n# numpy는 sliding_window_implementation 셀에서 이미 import 됨\n\n# 데이터 생성\nnp.random.seed(42)\ndata = np.sin(0.2 * np.arange(0, 100)) + np.random.normal(0, 0.1, 100)\noutliers = [20, 50, 80]\ndata[outliers] += [3, -3, 2]\n\n# 슬라이딩 윈도우 적용\nwindow_size = 10\nwindows = sliding_window(data, window_size) # (N, L) -> (N, window_size)\nwindows = windows[..., np.newaxis]  # (N, L, C) -> (N, window_size, 1)\n# PyTorch Conv1d는 (N, C, L) 입력을 기대하므로 차원 변경\nwindows = windows.transpose(0, 2, 1) # (N, C, L) -> (N, 1, window_size)\nprint(f\"윈도우 데이터 형태 (N, C, L): {windows.shape}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n윈도우 데이터 형태 (N, C, L): (91, 1, 10)\n```\n:::\n:::\n\n\n::: {#cnn-autoencoder-creation .cell execution_count=5}\n``` {.python .cell-code}\nimport torch.optim as optim # PyTorch 옵티마이저\n\n# 모델 생성\n# input_shape은 (window_size, 1) 이어야 합니다. (sequence_length, num_features)\n# data-generation 셀에서 windows는 (N, 1, window_size) 형태로 준비됨.\n# CNNAutoencoder의 __init__은 input_shape=(window_size, 1)을 받아 input_shape[1]=1을 in_channels로 사용.\nmodel_input_shape = (window_size, 1) # (sequence_length, num_features)\nmodel = CNNAutoencoder(model_input_shape) # cnn-autoencoder-definition 셀에서 정의된 클래스 사용\n\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.MSELoss() # 평균 제곱 오차 손실\n\nprint(\"PyTorch 모델 구조:\")\nprint(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPyTorch 모델 구조:\nCNNAutoencoder(\n  (encoder_conv1): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n  (encoder_relu1): ReLU()\n  (encoder_pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (encoder_conv2): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n  (encoder_relu2): ReLU()\n  (encoder_pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (decoder_conv_t1): ConvTranspose1d(16, 16, kernel_size=(4,), stride=(2,), padding=(1,), output_padding=(1,))\n  (decoder_relu1): ReLU()\n  (decoder_conv_t2): ConvTranspose1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n  (decoder_relu2): ReLU()\n  (decoder_conv_final): Conv1d(32, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n  (sigmoid): Sigmoid()\n)\n```\n:::\n:::\n\n\n### 모델 학습\n\n정상 데이터만 사용해 모델을 학습합니다:\n\n::: {#model-training .cell execution_count=6}\n``` {.python .cell-code}\n# torch는 cnn-autoencoder-definition 셀에서 이미 import 됨\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# 정상 데이터로 학습\n# 'outliers'는 원본 'data' 배열의 인덱스입니다.\n# 'windows' 배열에서 이상치가 포함된 윈도우를 식별하여 제외합니다.\ncontaminated_window_indices = set()\n# 'outliers', 'window_size', 'windows' 변수는 이전 셀들에서 정의되어 있어야 합니다.\nfor outlier_data_idx in outliers: \n    start_contaminated_win_idx = max(0, outlier_data_idx - window_size + 1)\n    end_contaminated_win_idx = outlier_data_idx \n    \n    for win_idx in range(start_contaminated_win_idx, end_contaminated_win_idx + 1):\n        if win_idx < len(windows): # 윈도우 인덱스가 유효한 범위 내에 있는지 확인\n            contaminated_window_indices.add(win_idx)\n\nnormal_windows_mask = np.ones(len(windows), dtype=bool)\nif contaminated_window_indices: # set이 비어있지 않은 경우에만 인덱싱\n    normal_windows_mask[list(contaminated_window_indices)] = False\n\nnormal_windows_np = windows[normal_windows_mask]\n\nif len(normal_windows_np) == 0:\n    print(\"경고: 학습에 사용할 정상 윈도우가 없습니다. Outlier 정의, window_size 또는 데이터 길이를 확인하세요.\")\nelse:\n    # PyTorch 데이터셋 및 로더 준비\n    normal_windows_torch = torch.tensor(normal_windows_np, dtype=torch.float32)\n    train_dataset = TensorDataset(normal_windows_torch) # 오토인코더는 입력과 타겟이 동일\n    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\n    # 모델 학습\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n    model.to(device)\n    \n    epochs = 50 # 에포크 수 설정\n    print_every_epochs = 10\n\n    model.train() # 학습 모드\n    for epoch in range(epochs):\n        epoch_loss = 0\n        for batch_data_list in train_loader:\n            inputs = batch_data_list[0].to(device)\n            targets = inputs # 오토인코더의 타겟은 입력과 동일\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            \n            epoch_loss += loss.item() * inputs.size(0) # 배치 손실 누적 (loss.item()은 평균 손실)\n        \n        epoch_loss /= len(train_loader.dataset) # 에포크 평균 손실\n        if (epoch + 1) % print_every_epochs == 0:\n            print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.6f}\")\n    print(\"모델 학습 완료.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUsing device: cpu\nEpoch [10/50], Loss: 0.485761\nEpoch [20/50], Loss: 0.230847\nEpoch [30/50], Loss: 0.215341\nEpoch [40/50], Loss: 0.208849\nEpoch [50/50], Loss: 0.207247\n모델 학습 완료.\n```\n:::\n:::\n\n\n### 재구성 오차 계산 및 이상치 탐지\n\n학습된 모델로 데이터를 복원하고, 재구성 오차를 계산합니다:\n\n::: {#reconstruction-error .cell execution_count=7}\n``` {.python .cell-code}\n# torch 및 numpy는 이전 셀들에서 이미 import 됨\n\n# 재구성 오차 계산\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval() # 평가 모드\n\n# 전체 windows 데이터를 PyTorch 텐서로 변환하고 device로 이동\nall_windows_torch = torch.tensor(windows, dtype=torch.float32).to(device)\n\n# 메모리 부족을 방지하기 위해 배치 단위로 처리할 수 있으나, 현재 데이터는 작으므로 한번에 처리\nwith torch.no_grad(): # 그래디언트 계산 비활성화\n    reconstructed_torch = model(all_windows_torch)\n\n# 결과를 CPU로 옮기고 NumPy 배열로 변환\nreconstructed_np = reconstructed_torch.cpu().numpy()\n\n# MAE (Mean Absolute Error) 계산\n# 원본 windows (numpy 배열)와 reconstructed_np 모두 (N, 1, window_size) 형태\n# axis=(1, 2)는 채널과 시퀀스 길이에 대한 평균을 의미\nmae = np.mean(np.abs(windows - reconstructed_np), axis=(1, 2))\nprint(f\"계산된 MAE 값 (처음 5개): {mae[:5]}\")\n\n# 이상치 탐지를 위한 임계값 설정 (데이터 및 모델 성능에 따라 조정 필요)\n# 예: MAE의 평균 + (표준편차 * 특정 배수) 또는 분위수 사용\nthreshold = np.mean(mae) + 1.5 * np.std(mae) # 표준편차 배수를 2에서 1.5로 줄여 민감도 증가\nprint(f\"이상치 탐지 임계값 (MAE): {threshold:.4f}\")\n\nanomalies_indices_in_windows = np.where(mae > threshold)[0] # 윈도우 배열 내의 인덱스\n\nprint(f\"이상치로 탐지된 윈도우의 수: {len(anomalies_indices_in_windows)}\")\nprint(f\"이상치로 탐지된 윈도우 인덱스: {anomalies_indices_in_windows}\")\n\n# 윈도우 인덱스를 원본 데이터 인덱스로 대략적으로 매핑 (윈도우의 시작점 기준)\n# 실제 이상치 발생 시점과 정확히 일치하지 않을 수 있음\nanomalies_approx_original_indices = anomalies_indices_in_windows \n# 좀 더 정확하게는 윈도우의 중간 지점 등을 고려할 수 있으나, 여기서는 시작점으로 단순화\n# anomalies_approx_original_indices = [idx + window_size // 2 for idx in anomalies_indices_in_windows]\nprint(f\"원본 데이터의 대략적인 이상치 인덱스 (윈도우 시작점 기준): {anomalies_approx_original_indices}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n계산된 MAE 값 (처음 5개): [0.10953805 0.09630316 0.0786427  0.0780262  0.07156017]\n이상치 탐지 임계값 (MAE): 0.9568\n이상치로 탐지된 윈도우의 수: 8\n이상치로 탐지된 윈도우 인덱스: [17 18 19 20 47 48 49 50]\n원본 데이터의 대략적인 이상치 인덱스 (윈도우 시작점 기준): [17 18 19 20 47 48 49 50]\n```\n:::\n:::\n\n\n### 결과 시각화\n\n::: {#visualization .cell execution_count=8}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 4))\nplt.plot(data, label='원본 데이터', alpha=0.7) # 'data'는 data-generation에서 정의됨\nplt.scatter(outliers, data[outliers], color='red', s=100, label='실제 이상치 (Ground Truth)', marker='o', edgecolors='black') # 'outliers'는 data-generation에서 정의됨\n\n# anomalies_approx_original_indices가 비어있을 수 있으므로 확인\nif len(anomalies_approx_original_indices) > 0:\n    # 탐지된 이상치 표시는 윈도우의 시작점을 기준으로 함\n    plt.scatter(anomalies_approx_original_indices, data[anomalies_approx_original_indices], \n                color='orange', marker='x', s=80, label='탐지된 이상치 (모델 예측)', alpha=0.8)\nelse:\n    print(\"탐지된 이상치가 없습니다.\")\n        \nplt.legend()\nplt.title('PyTorch CNN 오토인코더 기반 시계열 이상 탐지')\nplt.xlabel('시간 스텝')\nplt.ylabel('값')\nplt.grid(True, linestyle='--', alpha=0.6)\nplt.show()\n\n# 재구성 오차(MAE) 시각화\nplt.figure(figsize=(10, 3))\nplt.plot(mae, label='재구성 오차 (MAE)', color='green')\nplt.axhline(threshold, color='red', linestyle='--', label=f'임계값 ({threshold:.2f})')\nplt.title('윈도우별 재구성 오차 (MAE) 및 임계값')\nplt.xlabel('윈도우 인덱스')\nplt.ylabel('MAE')\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.6)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![PyTorch CNN 오토인코더 기반 이상 탐지 결과](index_files/figure-html/visualization-output-1.png){#visualization-1 width=834 height=389}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/visualization-output-2.png){#visualization-2 width=840 height=311}\n:::\n:::\n\n\n### 탐지 결과 분석 및 고려사항\n\n시각화 결과와 재구성 오차 검토 시 다음 사항을 고려해야 한다.\n\n1.  **실제 이상치 vs. 탐지 이상치**:\n    *   `data-generation` 단계에서 의도적으로 넣은 실제 이상치(`outliers = [20, 50, 80]`)와 모델의 탐지 결과는 다를 수 있다.\n    *   모든 실제 이상치가 탐지되지 않거나, 정상이 이상치로 잘못 탐지될 가능성이 항상 존재한다.\n    *   현 예제는 임계값(`np.mean(mae) + 1.5 * np.std(mae)`) 조정을 통해 최소 하나의 이상치를 탐지하도록 유도했다. 실제 상황에서는 모델 성능, 데이터 특성, `window_size`, 임계값 설정에 따라 결과가 크게 달라진다.\n\n2.  **윈도우 경계 효과 (Edge Effects)**:\n    *   시계열 데이터의 시작과 끝 부분 윈도우는 내부 윈도우에 비해 정보가 불완전할 수 있다 (이전/이후 데이터 부재).\n    *   CNN 모델, 특히 패딩 사용 시, 경계 영역 윈도우는 학습된 주 정상 패턴과 달라 재구성 오차가 상대적으로 커질 수 있다.\n    *   결과적으로, **시계열 양 끝부분에서 이상치가 아닌데도 이상치로 탐지되는 경향**이 나타날 수 있다. MAE 그래프에서 초반 또는 후반부에 높은 오차가 관찰된다면 이 효과를 의심해볼 수 있다.\n\n3.  **`window_size`의 중요성**:\n    *   `window_size`는 모델이 학습할 패턴의 길이를 결정한다.\n    *   너무 작으면 장기 패턴 파악이 어렵고, 너무 크면 짧은 순간의 이상치를 놓치거나 정상 변동에도 민감하게 반응할 수 있다.\n    *   현재 `window_size=10`으로 설정했다. 데이터 특성에 맞춰 이 값을 조정하며 실험하는 과정이 중요하다.\n\n4.  **모델 및 임계값의 한계**:\n    *   여기서 사용한 CNN 오토인코더는 비교적 단순한 모델이다.\n    *   더 복잡한 패턴이나 다양한 유형의 이상치를 탐지하려면 모델 구조 개선(예: LSTM, Transformer 기반 오토인코더)이나 다른 접근법을 고려해야 한다.\n    *   고정 임계값 대신 동적 임계값을 사용하거나, 통계적 검정 기법을 결합하는 것도 탐지 성능을 높이는 데 도움이 될 수 있다.\n\n이런 점들을 고려해 모델 결과를 해석해야 하며, 실제 문제 적용 시에는 충분한 검증과 실험이 필수다.\n\n## 결론 및 다음 단계\n\n이번 주에는 PyTorch로 간단한 1D CNN 오토인코더를 만들고, 시계열 이상 탐지를 수행했다. 이 모델은 시계열 이상 탐지의 괜찮은 시작점이 될 수 있다. 재구성 오차를 기반으로 이상치를 찾는 과정과, 임계값 설정에 따라 탐지 결과가 어떻게 달라지는지 확인했다.\n\n다음 포스트에서는 실제 산업 데이터를 사용해 모델을 학습시키고, 성능을 개선할 다양한 방법(예: 더 복잡한 모델 구조, 다른 유형의 오토인코더, 동적 임계값 설정 등)을 살펴볼 예정이다.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}